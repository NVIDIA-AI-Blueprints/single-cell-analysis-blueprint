name: ipynb Runner - Johnny Testing
run-name: ${{ github.actor }} is running ipynb tester

on:
  push:
    branches:
      - johnnynv-patch-dev
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deploy Environment'
        required: true
        default: 'staging'
      debug_from_step:
        description: 'Start from step (e.g. "load-docker")'
        required: false
        default: ''

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-notebook:
    # runs-on: ubuntu-latest
    runs-on: arc-runner-set-oke-org-poc
    # runs-on: arc-runner-set-oke-org-nv-ai-bp
    env:
      DOCKER_IMG_NAME: "nvcr.io/nvidia/rapidsai/notebooks"
      DOCKER_IMG_TAG: "25.06-cuda12.8-py3.12"
      DOCKER_COMPOSE_FILE: "${{ github.workspace }}/docker/brev/docker-compose-nb-2504.yaml"
      DOCKER_CACHE_PATH: "/tmp/docker-pull-cache"
      NOTEBOOK_PATH: "./notebooks/01_scRNA_analysis_preprocessing.ipynb"
      PYTHON_VERSION: "3.12"
    steps:  
      - name: Set global vars
        id: set_global_vars  # 必须指定 id，以便后续步骤引用
        run: |
          DOCKER_IMG_CACHE_NAME=$(echo "$DOCKER_IMG_NAME:$DOCKER_IMG_TAG" | sed 's/[\/:@.]/_/g')
          echo "Cache filename: ${DOCKER_IMG_CACHE_NAME}.tar"

          echo "docker_img_cache_name=${DOCKER_IMG_CACHE_NAME}" >> $GITHUB_OUTPUT

      - name: Checkout BP repository
        uses: actions/checkout@v4
        
      - run: |
          echo "repo path is: ${{ github.workspace }}"
          ls -la "${{ github.workspace }}"
      
      - name: Debug Info
        run: |
          echo "=============Debug Info======================"
          pwd
          ls -al .
          echo "=============Debug Info======================"
     
      - uses: ./.github/actions/setup-env
        with:
          python-version: '3.12'
          check-disk: 'false'

      - name: Setup docker env
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
        run: |
          # Install wget
          sudo apt-get update
          sudo apt-get install wget
          # Install Docker and Docker Compose in a single step
          curl -fsSL https://get.docker.com -o get-docker.sh
          sudo sh get-docker.sh
          sudo apt-get update
          sudo apt-get install -y docker-compose-plugin docker-compose build-essential
          # Get System Info
          echo "===================== System Info ====================="
          more /etc/os-release
          nvidia-smi
          docker version
          docker compose version

      - uses: ./.github/actions/check-sysinfo

      - name: Ensure cache directory exists
        run: |
          mkdir -p ${{ env.DOCKER_CACHE_PATH }}
          sudo chown -R $(id -u):$(id -g) /tmp/docker-pull-cache
          ls -ld /tmp/docker-pull-cache

      - name: Cache Docker image
        id: cache-docker-image
        if: ${{ always() }}
        uses: actions/cache@v3
        with:
          path: ${{ env.DOCKER_CACHE_PATH }}
          key: ${{ runner.os }}-docker-${{ env.DOCKER_IMG_TAG }}-nb-cuda
          restore-keys: |
            ${{ runner.os }}-docker-${{ env.DOCKER_IMG_TAG }}-
            ${{ runner.os }}-docker-
      
      - name: Debug info
        run: |
          echo "Primary Key: ${{ steps.cache-docker-image.outputs.cache-primary-key || 'N/A' }}"
          echo "Cache Hit: ${{ steps.cache-docker-image.outputs.cache-hit || 'false' }}"
          echo "Cache Path: ${{ env.DOCKER_CACHE_PATH }}"
          ls -la ${{ env.DOCKER_CACHE_PATH }}
        
      - name: Load cached docker image
        if: steps.cache-docker-image.outputs.cache-hit == 'true'
        run: |
          DOCKER_CACHE_PATH="${{ env.DOCKER_CACHE_PATH }}"
          DOCKER_IMG_CACHE_NAME="${{ steps.set_global_vars.outputs.docker_img_cache_name }}"
          echo "Cached file with path: $DOCKER_CACHE_PATH/$DOCKER_IMG_CACHE_NAME"

          if [ -f "${DOCKER_CACHE_PATH}/${DOCKER_IMG_CACHE_NAME}.tar"]; then
            echo "[Info]: the docker image cache exists, just load it from cache"
            docker load -i "${DOCKER_CACHE_PATH}/${DOCKER_IMG_CACHE_NAME}".tar
            echo "[Info]: the docker image cache exists, just load it from cache --- Done"
          fi

      - name: Pull docker image
        run: |
          start_time=$(date +%s)

          DOCKER_IMG_NAME="${{ env.DOCKER_IMG_NAME }}"
          DOCKER_IMG_TAG="${{ env.DOCKER_IMG_TAG }}"
          DOCKER_CACHE_PATH="${{ env.DOCKER_CACHE_PATH }}"
          DOCKER_IMG_CACHE_NAME="${{ steps.set_global_vars.outputs.docker_img_cache_name }}"

          echo "Docker image will use: $DOCKER_IMG_NAME:$DOCKER_IMG_TAG"
          
          if ! docker image inspect $DOCKER_IMG_NAME:$DOCKER_IMG_TAG >/dev/null 2>&1; then
            echo "[Info]: the docker image cache does NOT exists, just pull it from remote"
            if ! docker pull "$DOCKER_IMG_NAME:$DOCKER_IMG_TAG"; then
              echo "Pull failed, retrying..." 
              sleep 10
              docker pull --quiet "$DOCKER_IMG_NAME:$DOCKER_IMG_TAG" || {
                echo "Error: Docker pull failed after retry"
                exit 1
              }
            fi
          fi

          echo "[Info]: the docker image cache does NOT exists, just pull it from remote --- Done"
          
          mkdir -p ${DOCKER_CACHE_PATH}
          echo "[Info]: the docker image pull done, save it to cache path now"
          docker save $DOCKER_IMG_NAME:$DOCKER_IMG_TAG > ${DOCKER_CACHE_PATH}/${DOCKER_IMG_CACHE_NAME}.tar
          ls -alh ${DOCKER_CACHE_PATH}
          echo "[Info]: the docker image pull done, save it to cache path now --- Done"
          
          end_time=$(date +%s)
          echo "Execution time: $((end_time - start_time)) seconds"
        timeout-minutes: 20

      - name: Verify cache
        run: |
          DOCKER_CACHE_PATH="${{ env.DOCKER_CACHE_PATH }}"
          du -sh ${DOCKER_CACHE_PATH}/*

      - name: Start container
        run: |
          start_time=$(date +%s)
          docker images -a
          echo "Docker compose will use file: $DOCKER_COMPOSE_FILE"
          
          
          DOCKER_IMG_TAG="${{ env.DOCKER_IMG_TAG }}"
          export DOCKER_IMG_TAG=$DOCKER_IMG_TAG
          # export HOST_PIP_CACHE_DIR="$HOME/.cache/pip"
          export NOTEBOOKS_HOST_PATH="${{ github.workspace }}"

          echo "DOCKER_IMG_TAG: $DOCKER_IMG_TAG"
          echo "NOTEBOOKS_HOST_PATH: $NOTEBOOKS_HOST_PATH"
          echo "Workspace path: $GITHUB_WORKSPACE"
          echo "Workspace path: ${{ github.workspace }}"

          pwd
          ls -al ./

          set -e
          export COMPOSE_HTTP_TIMEOUT=300
          docker compose --verbose -f "$DOCKER_COMPOSE_FILE" up -d --wait --force-recreate
          
          end_time=$(date +%s)
          echo "Execution time: $((end_time - start_time)) seconds"

      - name: Check containers status
        run: |
          docker ps -a
          docker inspect <container_name> | grep -A 10 ExitCode
          docker compose -f "$DOCKER_COMPOSE_FILE" logs --no-color --tail=200 > docker-logs.txt
          cat docker-logs.txt

      - name: Debug Info
        run: |
          echo "=============Debug Info======================"
          docker compose -f "$DOCKER_COMPOSE_FILE" config --services
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend whoami
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend pwd
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al .
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend find . -maxdepth 2 | sed -e 's|[^/]*/|- |g' -e 's|^\./||'

          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/rapids
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cat /home/rapids/entrypoint.sh
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend pip list
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend df -lh

          echo "=============Debug Info======================"

      - name: Run Jupyter Notebook
        id: run-jupyter-notebook
        timeout-minutes: 30
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
          NVIDIA_API_KEY: ${{ secrets.NGC_API_KEY }}
          NGC_CLI_API_KEY: ${{ secrets.NGC_API_KEY }}
          VENV_PATH: "/opt/venv"
        run: |
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend python --version
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend python3 --version

          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend whoami
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend pwd
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/rapids
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/rapids/notebooks/
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /tmp/
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /tmp/app/
          # docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend mkdir -p /home/rapids/app/
          # docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/rapids/app/
          # docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cp -rv /tmp/app/ /home/rapids/app/
          # docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al /home/rapids/app/

          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend bash -c "
            cd ~/app/

            set -e
            # echo '=== Creating clean virtual environment ==='
            # python -m venv $VENV_PATH --clear
            # source $VENV_PATH/bin/activate

            echo '=== Upgrading pip and cleaning old installations ==='
            python -m pip install --upgrade pip
            # pip cache purge
            # rm -rf /root/.cache/pip

            echo '=== Installing requirements ==='
            pip install --no-cache-dir -r ./requirements.txt
            pip install --no-cache-dir papermill

            echo '=== Verifying installations ==='
            pip list

            # echo '=== Registering Jupyter kernel ==='
            # python -m ipykernel install --user --name python3 --display-name 'Python 3'
      
            echo '=== Verifying kernel ==='
            jupyter kernelspec list
          "

          echo "=============== Executing notebook ====================="
          OUTPUT_NOTEBOOK="~/app/result.ipynb"
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend bash -c "
            cd ~/app/

            # source $VENV_PATH/bin/activate && \
            papermill '$NOTEBOOK_PATH' '$OUTPUT_NOTEBOOK' \
              --log-output \
              --log-level DEBUG \
              --progress-bar \
              --report-mode \
              --kernel python3
          "

          echo "===============show content of nb====================="
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cat "$OUTPUT_NOTEBOOK"
          echo "===============show content of nb====================="
          
      - name: Convert result to html format
        if: steps.run-jupyter-notebook.outcome == 'success'
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
        run: |
          echo "Run jupyter notebook succeeded, running Convert result to HTML format"
          OUTPUT_NOTEBOOK="~/app/result.ipynb"
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend jupyter nbconvert --to html "$OUTPUT_NOTEBOOK"
          echo "===============show content of nb html====================="
          docker compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cat ./result.html
          echo "===============show content of nb html====================="

      # - name: Checkout Test repository
      #   uses: actions/checkout@v4
      #   with:
      #     repository: 'NVIDIA-AI-Blueprints/blueprint-github-test'
      #     token: ${{ secrets.BLUEPRINT_GITHUB_TEST }}
      #     path: blueprint-github-test-tmp
          
      # - name: Install Poetry/Dependencies and execute test
      #   run: |
      #     cd blueprint-github-test-tmp
      #     curl -sSL https://install.python-poetry.org | python3 -          
      #     $HOME/.local/bin/poetry install
      #     source $($HOME/.local/bin/poetry env info --path)/bin/activate
      #     rm -rf input/*
      #     cp ../result.html input/1_Deploy_LLM_Router.html
      #     ls -l input/
      #     pytest -m llm_router --disable-warnings
                             
      # - name: Upload the result notebook as artifact
      #   if: always()
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: result-notebook
      #     path: "result.html"
      #     retention-days: 30

      - name: Stop containers
        if: ${{ always() }}
        run: docker compose -f "$DOCKER_COMPOSE_FILE" down

      - name: Clean up
        if: always()
        run: |
          docker system prune -f
          sudo rm -rf "${{ env.DOCKER_CACHE_PATH }}"
          