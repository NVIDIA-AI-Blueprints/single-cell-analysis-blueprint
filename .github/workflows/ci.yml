name: ipynb Runner - Johnny Testing
run-name: ${{ github.actor }} is running ipynb tester

on:
  push:
    branches:
      - johnnynv-patch-dev
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deploy Environment'
        required: true
        default: 'staging'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-notebook:
    # runs-on: ubuntu-latest
    runs-on: arc-runner-set-oke-org-poc
    # runs-on: arc-runner-set-oke-org-nv-ai-bp
    env:
      DOCKER_COMPOSE_FILE: ./docker/brev/docker-compose-nb-2504.yaml 
      NOTEBOOK_PATH: ./notebooks/01_scRNA_analysis_preprocessing.ipynb
      PYTHON_VERSION: 3.12
    steps:  
      - name: Checkout BP repository
        uses: actions/checkout@v4
        
      - run: |
          echo "repo path is: ${{ github.workspace }}"
          ls -la "${{ github.workspace }}"
      
      - name: Debug Info
        run: |
          echo "=============Debug Info======================"
          pwd
          ls -al .
          echo "=============Debug Info======================"
     
      - uses: ./.github/actions/check-sysinfo

      # - uses: ./.github/actions/setup-env
      #   with:
      #     python-version: '3.12'
      #     check-disk: 'false'

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            **/*.ipynb
            
      - name: Install dependencies
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install papermill
          pip install ipywidgets
          pip install torch
          # Install wget
          sudo apt-get update
          sudo apt-get install wget
          # Install Docker and Docker Compose in a single step
          curl -fsSL https://get.docker.com -o get-docker.sh
          sudo sh get-docker.sh
          sudo apt-get update
          sudo apt-get install -y docker-compose-plugin docker-compose build-essential
          # Get System Info
          echo "===================== System Info ====================="
          more /etc/os-release
          nvidia-smi
          docker version
          docker compose version

      - name: Pull large image first
        run: |
          # export COMPOSE_HTTP_TIMEOUT=600
          docker pull nvcr.io/nvidia/rapidsai/notebooks:25.06-cuda12.8-py3.12

      - name: Start container
        run: |
          docker images -a
          echo "Docker compose will use file: $DOCKER_COMPOSE_FILE"
          
          export COMPOSE_HTTP_TIMEOUT=300
          export NOTEBOOKS_HOST_PATH="${{ github.workspace }}"
          docker compose --verbose -f "$DOCKER_COMPOSE_FILE" up -d

      - name: Debug container logs
        if: ${{ failure() }}
        run: |
          docker ps -a
          # docker system df
          # docker stats
          docker logs brev_backend_1

      - name: Check running containers
        run: docker ps -a

      - name: Debug Info
        run: |
          echo "=============Debug Info======================"
          docker-compose -f "$DOCKER_COMPOSE_FILE" config --services
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend pwd
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend ls -al .
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend find . -maxdepth 3 | sed -e 's|[^/]*/|- |g' -e 's|^\./||'
          echo "=============Debug Info======================"

      - name: Stop containers
        if: ${{ always() }}
        run: docker-compose -f "$DOCKER_COMPOSE_FILE" down
          
      - name: Run Jupyter Notebook
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
          NVIDIA_API_KEY: ${{ secrets.NGC_API_KEY }}
          NGC_CLI_API_KEY: ${{ secrets.NGC_API_KEY }}
        run: |
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend python --version
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend python3 --version

          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend pip install ipykernel
          # docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend python -m ipykernel install --user --name python3 --display-name "python3"
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend jupyter kernelspec list

          OUTPUT_NOTEBOOK="result.ipynb"
          echo "Executing notebook: $NOTEBOOK_PATH"
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend papermill "$NOTEBOOK_PATH" "$OUTPUT_NOTEBOOK" --log-output --log-level DEBUG
          echo "===============show content of nb====================="
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cat "$OUTPUT_NOTEBOOK"
          echo "===============show content of nb====================="
          
      - name: Convert result to html format
        if: always()
        env:
          NGC_API_Key: ${{ secrets.NGC_API_KEY }}
        run: |
          OUTPUT_NOTEBOOK="result.ipynb"
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend jupyter nbconvert --to html "$OUTPUT_NOTEBOOK"
          echo "===============show content of nb html====================="
          docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T backend cat ./result.html
          echo "===============show content of nb html====================="

      # - name: Checkout Test repository
      #   uses: actions/checkout@v4
      #   with:
      #     repository: 'NVIDIA-AI-Blueprints/blueprint-github-test'
      #     token: ${{ secrets.BLUEPRINT_GITHUB_TEST }}
      #     path: blueprint-github-test-tmp
          
      # - name: Install Poetry/Dependencies and execute test
      #   run: |
      #     cd blueprint-github-test-tmp
      #     curl -sSL https://install.python-poetry.org | python3 -          
      #     $HOME/.local/bin/poetry install
      #     source $($HOME/.local/bin/poetry env info --path)/bin/activate
      #     rm -rf input/*
      #     cp ../result.html input/1_Deploy_LLM_Router.html
      #     ls -l input/
      #     pytest -m llm_router --disable-warnings
                             
      # - name: Upload the result notebook as artifact
      #   if: always()
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: result-notebook
      #     path: "result.html"
      #     retention-days: 30
